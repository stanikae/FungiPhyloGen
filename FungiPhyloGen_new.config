

params {
  inputDir = "/spaces/stanford/ChibuikeCandidaAurisWGS/fungiphylogen"
  resultsDir = "$inputDir/results"
  // bcftl = "$resultsDir"
  samplesheet  = "$inputDir/samplesheet.csv" 
  refseq = "$inputDir/ref/Clade_I_B8441.fna"
  gbk = "$inputDir/ref/Clade_I_B8441.gbff"
  ploidy = 1
  threads = 12
  prjName = "PRJ01"
  genus = "default" // "cauris" 
  cleanreadsDir = ""
  readsDir = "" 
  index = ""
  trm = "${params.resultsDir}/trimmed"
  bcftl = "${params.resultsDir}/variants"
  ann = "${params.resultsDir}/snpeff_annotation"
  iq = "${params.resultsDir}/iqtree_phylogeny"
  dist = "${params.resultsDir}/snp_distances"
  nj = "${params.resultsDir}/rapidnj_tree"
  skip_trimming = false  
  // Use --skip_trimming true if you are using previously filtered reads

  
  // Define expressions for BAD variants (Exclude logic)
    // REMOVED: FS>60.0 (Strand bias is handled implicitly by QUAL<30)
    
    filters = [
        'default'       : 'TYPE!="snp" || QUAL<30 || MQ<40 || INFO/DP<10 || (QUAL/INFO/DP)<2.0',   
        'cparapsilosis' : 'TYPE!="snp" || QUAL<30 || MQ<40 || INFO/DP<10 || (QUAL/INFO/DP)<2.0',
        'cauris'        : 'TYPE!="snp" || QUAL<30 || MQ<40 || INFO/DP<10 || (QUAL/INFO/DP)<2.0',
        'wanomalus'     : 'TYPE!="snp" || QUAL<30 || MQ<40 || INFO/DP<10 || (QUAL/INFO/DP)<2.0 || INFO/AF<0.9',
        'cneoformans'   : 'TYPE!="snp" || QUAL<30 || MQ<40 || INFO/DP<10 || (QUAL/INFO/DP)<2.0 || INFO/AF<0.9'
    ]
 
}

workDir = "$params.inputDir/work"

params.cacheDir = "/spaces/stanford/anaconda3/envs" 
params.condaPath = "/spaces/stanford/anaconda3/envs"
params.PICARD = "$params.cacheDir/fpgAlign/share/picard-2.27.4-0"

process.executor = 'slurm'

executor {
    name = 'slurm'
    queueSize = 30
    submitRateLimit = '3 sec'
    
}


conda.enabled = true


// nextflow run ~/git-repos/FungiPhyloGen/main_fpg.nf --refseq $refseq --gbk $gbk --prjName "FPG-TEST" -c $config -with-conda true -resume

/*
conda {
  params.cacheDir = "$HOME/anaconda3/envs" 
  //Defines the path where Conda environments are stored. 
  //When using a compute cluster make sure to provide a shared file system path accessible from all compute nodes.

}
*/


/*
profiles {

    standard {
        process.executor = 'local'
        process.cpus = 5
        process.memory = '10GB'
    }

    cluster {
        process.executor = 'slurm'
        //process.queue = 'main'
        //process.memory = '10GB'
    }
}
*/


/*
executor {
  name


}
*/
