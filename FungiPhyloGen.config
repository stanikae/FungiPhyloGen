/*
 * -------------------------------------------------
 * FungiPhyloGen Nextflow Config (Optimized)
 * -------------------------------------------------
 */

params {
    // =================================================================
    // Input/Output Defaults
    // =================================================================
    inputDir    = "${launchDir}"
    resultsDir  = "${launchDir}/results"
    samplesheet = "${params.inputDir}/samplesheet.csv"
    
    // Reference Files 
    refseq      = "${params.inputDir}/ref/Clade_I_B8441.fna"
    gbk         = "${params.inputDir}/ref/Clade_I_B8441.gbff"

    // Analysis Logic
    ploidy      = 1
    prjName     = "PRJ01"
    genus       = "cauris_small"
    
    // Sub-directories
    trm         = "${params.resultsDir}/trimmed"
    bcftl       = "${params.resultsDir}/variants"
    ann         = "${params.resultsDir}/snpeff_annotation"
    iq          = "${params.resultsDir}/iqtree_phylogeny"
    dist        = "${params.resultsDir}/snp_distances"
    nj          = "${params.resultsDir}/rapidnj_tree"

    // Toggles
    skip_trimming = false
    
    // =================================================================
    // Environment & Tool Paths
    // =================================================================
    // 1. Define the base Conda path (Default: Local Laptop)
    condaCacheDir = "${HOME}/anaconda3/envs"

    // 2. Define Picard relative to that base path
    // Note: If you change condaCacheDir in a profile, you must update this too!
    picard_jar  = "${params.condaCacheDir}/fpgAlign/share/picard-2.27.4-0/picard.jar"

    // =================================================================
    // Filter Logic Definition
    // =================================================================
    filters = [
        'cauris_small'    : 'TYPE!="snp" || MQ<40 || QUAL<30 || FS>60 || (MQSBZ < -2.0 || MQSBZ > 2.0) || (QUAL/INFO/DP)<0.035 || INFO/AF<0.75',
        'cauris_batch'    : 'TYPE!="snp" || MQ<40 || QUAL<30 || FS>60 || (MQSBZ < -2.0 || MQSBZ > 2.0) || (QUAL/INFO/DP)<0.035 || F_MISSING > 0.2',
        'wanomalus_small' : 'TYPE!="snp" || MQ<40 || QUAL<30 || FS>60 || (MQSBZ < -2.0 || MQSBZ > 2.0) || (QUAL/INFO/DP)<0.1 || INFO/AF<0.75 || F_MISSING > 0.4',
        'wanomalus_batch' : 'TYPE!="snp" || MQ<40 || QUAL<30 || FS>60 || (MQSBZ < -2.0 || MQSBZ > 2.0) || (QUAL/INFO/DP)<0.035 || INFO/AF<0.85',
        'cparapsilosis'   : 'TYPE!="snp" || MQ<40 || FS>60 || (MQSBZ < -2.0 || MQSBZ > 2.0) || (QUAL/MAX(AD[:1]))<=2.0 || DP<10',
        'cneoformans'     : 'TYPE!="snp" || MQ<40 || QUAL<30 || FS>60 || (MQSBZ < -2.0 || MQSBZ > 2.0) || (QUAL/INFO/DP)<0.035 || INFO/AF<0.75'
    ]

    // Default Resource Limits
    max_memory = '12.GB'
    max_cpus   = 4
    max_time   = '240.h'
}

// =================================================================
// Profiles
// =================================================================
profiles {
    
    // Local / Laptop Profile
    standard {
        process.executor = 'local'
        conda.enabled    = true
        conda.cacheDir   = params.condaCacheDir // Uses the default defined at top
        
        params.max_memory = '8.GB'
        params.max_cpus   = 4
    }

    // HPC / Slurm Profile
    slurm {
        process.executor     = 'slurm'
        process.queue        = 'batch' 
        executor.queueSize   = 30
        executor.submitRateLimit = '3 sec'
        
        conda.enabled        = true
        
        // --- CRITICAL FIX START ---
        // 1. Update the parameter variable so it points to the HPC path
        params.condaCacheDir = "/spaces/stanford/anaconda3/envs"
        
        // 2. Point the Nextflow directive to this new param
        conda.cacheDir       = params.condaCacheDir
        
        // 3. Re-evaluate picard_jar because the top-level definition 
        //    used the "old" ${HOME} value before this profile ran.
        params.picard_jar    = "${params.condaCacheDir}/fpgAlign/share/picard-2.27.4-0/picard.jar"
        // --- CRITICAL FIX END ---

        params.max_memory    = '128.GB'
        params.max_cpus      = 32
    }
    
    // Docker Profile
    docker {
        docker.enabled = true
        conda.enabled  = false
    }
}

// =================================================================
// Process Resource Configuration
// =================================================================
process {
    cpus   = { check_max( 2    * task.attempt, 'cpus'   ) }
    memory = { check_max( 6.GB * task.attempt, 'memory' ) }
    time   = { check_max( 4.h  * task.attempt, 'time'   ) }

    errorStrategy = { task.exitStatus in [143,137,104,134,139] ? 'retry' : 'finish' }
    maxRetries    = 3
}

// =================================================================
// Functions
// =================================================================
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
